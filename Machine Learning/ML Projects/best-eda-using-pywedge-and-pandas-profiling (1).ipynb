{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n!pip install pywedge\nimport pywedge as pw\n\n!pip3 install pandas_profiling --upgrade\nimport pandas_profiling as pp\nfrom pandas_profiling import ProfileReport\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-27T13:47:46.495487Z","iopub.execute_input":"2021-05-27T13:47:46.495867Z","iopub.status.idle":"2021-05-27T13:48:40.818838Z","shell.execute_reply.started":"2021-05-27T13:47:46.495834Z","shell.execute_reply":"2021-05-27T13:48:40.81779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:48:45.352864Z","iopub.execute_input":"2021-05-27T13:48:45.35328Z","iopub.status.idle":"2021-05-27T13:48:45.358295Z","shell.execute_reply.started":"2021-05-27T13:48:45.35324Z","shell.execute_reply":"2021-05-27T13:48:45.357406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train=pd.read_csv('/kaggle/input/titanic/train.csv')\ndf_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:48:48.880592Z","iopub.execute_input":"2021-05-27T13:48:48.881373Z","iopub.status.idle":"2021-05-27T13:48:48.938663Z","shell.execute_reply.started":"2021-05-27T13:48:48.881324Z","shell.execute_reply":"2021-05-27T13:48:48.937376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:48:52.20882Z","iopub.execute_input":"2021-05-27T13:48:52.209266Z","iopub.status.idle":"2021-05-27T13:48:52.215668Z","shell.execute_reply.started":"2021-05-27T13:48:52.209227Z","shell.execute_reply":"2021-05-27T13:48:52.214921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.columns","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:48:54.747531Z","iopub.execute_input":"2021-05-27T13:48:54.748132Z","iopub.status.idle":"2021-05-27T13:48:54.754364Z","shell.execute_reply.started":"2021-05-27T13:48:54.748093Z","shell.execute_reply":"2021-05-27T13:48:54.753285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:48:58.422613Z","iopub.execute_input":"2021-05-27T13:48:58.423024Z","iopub.status.idle":"2021-05-27T13:48:58.431948Z","shell.execute_reply.started":"2021-05-27T13:48:58.422973Z","shell.execute_reply":"2021-05-27T13:48:58.430859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.isna().sum().sort_values()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:49:01.619625Z","iopub.execute_input":"2021-05-27T13:49:01.620015Z","iopub.status.idle":"2021-05-27T13:49:01.631679Z","shell.execute_reply.started":"2021-05-27T13:49:01.619968Z","shell.execute_reply":"2021-05-27T13:49:01.630373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:49:06.333363Z","iopub.execute_input":"2021-05-27T13:49:06.333888Z","iopub.status.idle":"2021-05-27T13:49:06.358095Z","shell.execute_reply.started":"2021-05-27T13:49:06.333843Z","shell.execute_reply":"2021-05-27T13:49:06.357098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:49:09.539573Z","iopub.execute_input":"2021-05-27T13:49:09.540034Z","iopub.status.idle":"2021-05-27T13:49:09.586884Z","shell.execute_reply.started":"2021-05-27T13:49:09.539972Z","shell.execute_reply":"2021-05-27T13:49:09.585572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.describe().style.background_gradient(axis=1,cmap=sns.light_palette('green', as_cmap=True))","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:49:13.039604Z","iopub.execute_input":"2021-05-27T13:49:13.040011Z","iopub.status.idle":"2021-05-27T13:49:13.136188Z","shell.execute_reply.started":"2021-05-27T13:49:13.039959Z","shell.execute_reply":"2021-05-27T13:49:13.13496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# What is Pywedge?\nPywedge is an open-source python library which is a complete package that helps you in Visualizing the data, Pre-process the data and also create some baseline models which can be further tuned to make the best machine learning model for the data.\n\n***!pip install pywedge***\n\n***import pywedge as pw***","metadata":{}},{"cell_type":"code","source":"dash = pw.Pywedge_Charts(df_train, c=None, y='Survived')\ndashboard = dash.make_charts()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:49:18.52027Z","iopub.execute_input":"2021-05-27T13:49:18.520875Z","iopub.status.idle":"2021-05-27T13:49:23.071142Z","shell.execute_reply.started":"2021-05-27T13:49:18.520822Z","shell.execute_reply":"2021-05-27T13:49:23.069865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing the data","metadata":{}},{"cell_type":"markdown","source":"***loading the dataset***","metadata":{}},{"cell_type":"code","source":"df_train=pd.read_csv('../input/titanic/train.csv')\ndf_test=pd.read_csv('../input/titanic/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:49:29.226424Z","iopub.execute_input":"2021-05-27T13:49:29.226795Z","iopub.status.idle":"2021-05-27T13:49:29.249428Z","shell.execute_reply.started":"2021-05-27T13:49:29.226753Z","shell.execute_reply":"2021-05-27T13:49:29.248311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***we are here handle regression. so we use type='regression' , you can use classification as type for classification problem***","metadata":{}},{"cell_type":"code","source":"blm = pw.baseline_model(df_train, df_test, c=None, y='Survived', type='Regression')\nblm.Regression_summary()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:49:33.110599Z","iopub.execute_input":"2021-05-27T13:49:33.11103Z","iopub.status.idle":"2021-05-27T13:49:33.269422Z","shell.execute_reply.started":"2021-05-27T13:49:33.110978Z","shell.execute_reply":"2021-05-27T13:49:33.26828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#blm.predictions_baseline","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:50:24.071736Z","iopub.execute_input":"2021-05-27T13:50:24.072201Z","iopub.status.idle":"2021-05-27T13:50:24.092869Z","shell.execute_reply.started":"2021-05-27T13:50:24.07216Z","shell.execute_reply":"2021-05-27T13:50:24.091541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# pandas_profiling\nGenerates profile reports from a pandas DataFrame. The pandas df.describe() function is great but a little basic for serious exploratory data analysis. pandas_profiling extends the pandas DataFrame with df.profile_report() for quick data analysis.\n\n***For each column the following statistics - if relevant for the column type - are presented in an interactive HTML report:***\n\n*Type inference: detect the types of columns in a dataframe.*\n\n*Essentials: type, unique values, missing values*\n\n*Quantile statistics like minimum value, Q1, median, Q3, maximum, range, interquartile range*\n\n*Descriptive statistics like mean, mode, standard deviation, sum, median absolute deviation, coefficient of variation, kurtosis, skewness*\n\n***Most frequent values***\n\n    Histograms\n\n    Correlations highlighting of highly correlated variables, Spearman, Pearson and Kendall matrices\n\n    Missing values matrix, count, heatmap and dendrogram of missing values\n\n    Duplicate rows Lists the most occurring duplicate rows\n\n    Text analysis learn about categories (Uppercase, Space), scripts (Latin, Cyrillic) and blocks (ASCII) of text data","metadata":{}},{"cell_type":"code","source":"#import pandas_profiling as pp\n#from pandas_profiling import ProfileReport\npp.ProfileReport(df_train)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:50:39.67502Z","iopub.execute_input":"2021-05-27T13:50:39.675382Z","iopub.status.idle":"2021-05-27T13:51:00.015069Z","shell.execute_reply.started":"2021-05-27T13:50:39.67535Z","shell.execute_reply":"2021-05-27T13:51:00.012861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}